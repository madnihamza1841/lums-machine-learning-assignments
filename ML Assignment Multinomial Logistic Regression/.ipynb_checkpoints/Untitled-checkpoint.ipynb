{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "# from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading file to a dataframe\n",
    "file_data = pd.read_csv(\"Tweets.csv\")\n",
    "file_data\n",
    "\n",
    "# stop_words = [\"i\",\"me\",\"my\",\"myself\",\"we\",\"our\",\"ours\",\"ourselves\",\"you\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"he\",\"him\",\"his\",\"himself\",\"she\",\"her\",\"hers\",\"herself\",\"it\",\"its\",\"itself\",\"they\",\"them\",\"their\",\"theirs\",\"themselves\",\"what\",\"which\",\"who\",\"whom\",\"this\",\"that\",\"these\",\"those\",\"am\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"have\",\"has\",\"had\",\"having\",\"do\",\"does\",\"did\",\"doing\",\"a\",\"an\",\"the\",\"and\",\"but\",\"if\",\"or\",\"because\",\"as\",\"until\",\"while\",\"of\",\"at\",\"by\",\"for\",\"with\",\"about\",\"against\",\"between\",\"into\",\"through\",\"during\",\"before\",\"after\",\"above\",\"below\",\"to\",\"from\",\"up\",\"down\",\"in\",\"out\",\"on\",\"off\",\"over\",\"under\",\"again\",\"further\",\"then\",\"once\",\"here\",\"there\",\"when\",\"where\",\"why\",\"how\",\"all\",\"any\",\"both\",\"each\",\"few\",\"more\",\"most\",\"other\",\"some\",\"such\",\"no\",\"nor\",\"not\",\"only\",\"own\",\"same\",\"so\",\"than\",\"too\",\"very\",\"s\",\"t\",\"can\",\"will\",\"just\",\"don\",\"should\",\"now\"]\n",
    "stop_words = [\"a\",\"the\",\"me\",\"an\",\"and\",\"then\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION BEGINS HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2363 3099 9178\n"
     ]
    }
   ],
   "source": [
    "#Counting the number of data for each class \n",
    "count_pos = 0\n",
    "count_neu = 0\n",
    "count_neg = 0\n",
    "\n",
    "for i in file_data[\"airline_sentiment\"]:\n",
    "    if i == \"neutral\" :\n",
    "        count_neu+=1\n",
    "    elif i == \"positive\" :\n",
    "        count_pos+=1\n",
    "    elif i == \"negative\" :\n",
    "        count_neg+=1\n",
    "print(count_pos,count_neu,count_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to make a dictionary for bag of words\n",
    "\n",
    "\n",
    "# def is_emoji(s):\n",
    "#     return s in UNICODE_EMOJI\n",
    "# def add_space(text):\n",
    "#     return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()\n",
    "\n",
    "\n",
    "def get_unique_words(file):\n",
    "    words_dict ={}\n",
    "    for i in range(len(file)):\n",
    "        tweet = file['text'][i].lower()  #lower case\n",
    "        \n",
    "#         tweet = add_space(tweet)         #adding a space in between emojis\n",
    "        \n",
    "        tweet = tweet.replace(\",\",\" \")    #removing punctuation\n",
    "        tweet = tweet.replace(\".\",\" \")   \n",
    "        tweet = tweet.replace(\"!\",\" \")  \n",
    "        tweet = tweet.replace(\"?\",\" \")\n",
    "        tweet = tweet.replace(\"(\",\" \")\n",
    "        tweet = tweet.replace(\")\",\" \")\n",
    "        tweet = tweet.replace(\"'\",\" \")\n",
    "        tweet = tweet.replace(\"\\\"\",\" \")\n",
    "        tweet = tweet.replace(\"/\",\" \")\n",
    "        \n",
    "        tweet = tweet.split()\n",
    "        \n",
    "        for x in tweet:\n",
    "            if (x not in stop_words) and (x not in words_dict) and (\"@\" not in x) and (len(x)>=3):\n",
    "                words_dict[x] = 0\n",
    "    return words_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of bag of words on all tweets and returns a list of features + label \n",
    "def bag_of_words(file):\n",
    "    data = []  #data to be returned\n",
    "    \n",
    "    words_dict = get_unique_words(file) #get unique words\n",
    "    print(len(list(words_dict.values())))\n",
    "    \n",
    "    for i in range(len(file)):\n",
    "#         print(i)\n",
    "        \n",
    "        label = file['airline_sentiment'][i]\n",
    "        \n",
    "        tweet = file['text'][i].lower()  #lower case\n",
    "\n",
    "#         tweet = add_space(tweet)         #adding a space in between emojis\n",
    "        \n",
    "        tweet = tweet.replace(\",\",\" \")    #removing punctuation\n",
    "        tweet = tweet.replace(\".\",\" \")   \n",
    "        tweet = tweet.replace(\"!\",\" \")  \n",
    "        tweet = tweet.replace(\"?\",\" \")\n",
    "        tweet = tweet.replace(\"(\",\" \")\n",
    "        tweet = tweet.replace(\")\",\" \")\n",
    "        tweet = tweet.replace(\"'\",\" \")\n",
    "        tweet = tweet.replace(\"\\\"\",\" \")\n",
    "        tweet = tweet.replace(\"/\",\" \") \n",
    "\n",
    "        tweet = tweet.split()\n",
    "\n",
    "        temp_dict = words_dict.copy()  #creating a temp dictionary (shallow copy)\n",
    "        \n",
    "        for x in tweet:\n",
    "            if x in temp_dict:\n",
    "                temp_dict[x]+=1\n",
    "        values = list(temp_dict.values())\n",
    "        \n",
    "        if label == \"neutral\":\n",
    "            label = 0\n",
    "        elif label == \"positive\":\n",
    "            label =1\n",
    "        elif label == \"negative\":\n",
    "            label = -1\n",
    "        \n",
    "        data.append(values+[label])\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divides the data into pos neu and neg tweets and then allots 80 percent of each to train and rest to test\n",
    "#returns the train data, test data, train labels and test labels.\n",
    "def split_stratified(dataset):\n",
    "    \n",
    "    positive_features = []\n",
    "    neutral_features = []\n",
    "    negative_features = []\n",
    "    \n",
    "    positive_labels = []\n",
    "    neutral_labels = []\n",
    "    negative_labels = []\n",
    "    \n",
    "    for x in dataset:\n",
    "        if x[-1] == 1:\n",
    "            positive_features.append(x[:-1])\n",
    "            positive_labels.append([1,0,0])\n",
    "        elif x[-1] == 0:\n",
    "            neutral_features.append(x[:-1])\n",
    "            neutral_labels.append([0,1,0])\n",
    "        elif x[-1] == -1:\n",
    "            negative_features.append(x[:-1])\n",
    "            negative_labels.append([0,0,1])\n",
    "            \n",
    "    print(\"printing lengths\")\n",
    "    print(len(positive_features))\n",
    "    print(len(positive_features[:int(len(positive_features)*.8)]))\n",
    "    print(len(positive_features[int(len(positive_features)*.8):]))\n",
    "    print()\n",
    "    print(len(neutral_features))\n",
    "    print(len(neutral_features[:int(len(neutral_features)*.8)]))\n",
    "    print(len(neutral_features[int(len(neutral_features)*.8):]))\n",
    "    print()\n",
    "    print(len(negative_features))\n",
    "    print(len(negative_features[:int(len(negative_features)*.8)]))\n",
    "    print(len(negative_features[int(len(negative_features)*.8):]))\n",
    "    \n",
    "    train_features = positive_features[:int(len(positive_features)*.8)] + neutral_features[:int(len(neutral_features)*.8)] + negative_features[:int(len(negative_features)*.8)]\n",
    "    train_labels   = positive_labels[:int(len(positive_labels)*.8)] + neutral_labels[:int(len(neutral_labels)*.8)] + negative_labels[:int(len(negative_labels)*.8)]\n",
    "    \n",
    "    test_features  = positive_features[int(len(positive_features)*.8):] + neutral_features[int(len(neutral_features)*.8):] + negative_features[int(len(negative_features)*.8):]\n",
    "    test_labels    = positive_labels[int(len(positive_labels)*.8):] + neutral_labels[int(len(neutral_labels)*.8):] + negative_labels[int(len(negative_labels)*.8):]\n",
    "\n",
    "    return (np.array(train_features), np.array(train_labels), np.array(test_features), np.array(test_labels))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features shape = (no of tweets,unique words)\n",
    "\n",
    "labels shape = (no of tweets,unique classes)\n",
    "\n",
    "[positive, neutral, negaitve]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15903\n"
     ]
    }
   ],
   "source": [
    "data = bag_of_words(file_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing lengths\n",
      "2363\n",
      "1890\n",
      "473\n",
      "\n",
      "3099\n",
      "2479\n",
      "620\n",
      "\n",
      "9178\n",
      "7342\n",
      "1836\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels, test_features, test_labels = split_stratified(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11711, 15903)\n",
      "(11711, 3)\n",
      "(2929, 15903)\n",
      "(2929, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_features.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING BEGINS HERE...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta0, thetas):\n",
    "    print(X.shape)\n",
    "    print(theta0.shape)\n",
    "    print(thetas.shape)\n",
    "    return Softmax(theta0 + np.dot(X,thetas))    \n",
    "\n",
    "def CrossEntropy(p,y):\n",
    "    return (-1/y.size) * np.sum(y*np.log(p))\n",
    "\n",
    "def Softmax(x):\n",
    "    e_x = np.exp(x) \n",
    "    return (e_x.T / e_x.sum(axis=1)).T\n",
    "\n",
    "def computeCost(X, Y, theta0, thetas):\n",
    "    h_x = Softmax(theta0 + np.dot(X,thetas))\n",
    "    return CrossEntropy(h_x,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapes of Vectors used: \n",
    "\n",
    "X --> (N,C)   N: Number of tweets, C = Unique words in Dictionary (Bag of words)\n",
    "\n",
    "thetas --> (C,3) 3;number of classes\n",
    "\n",
    "theta0 --> (1,3)\n",
    "\n",
    "Output = (n,3)\n",
    "\n",
    "theta0 + np.dot(X,thetas)   ---->  (1,3) + (n,3)  = (n,3) ---> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch_gradientDescent(X, Y, alpha, n_epoch):\n",
    "#     m = Y.size\n",
    "#     J = list()  \n",
    "#     theta0 = np.array([0.0,0.0,0.0])\n",
    "#     thetas = np.zeros([X.shape[1],3])\n",
    "    \n",
    "#     for epoch in range(n_epoch):\n",
    "#         h_x = Softmax(theta0 + np.dot(X,thetas))\n",
    "        \n",
    "# #         print(theta0.shape)\n",
    "# #        print((h_x - Y).shape)\n",
    "# #         print(thetas.shape)\n",
    "#         theta0 = theta0 - (alpha) * np.dot(np.ones(X.shape[0]),h_x-Y)\n",
    "#         thetas = thetas - (alpha) * np.dot(np.transpose(X),h_x-Y)\n",
    "\n",
    "#         J.append(computeCost(X,Y,theta0,thetas))\n",
    "# #         print(\"Epoch: \",epoch+1, \"  J: \", J[-1])\n",
    "        \n",
    "# #         print(theta0.shape)\n",
    "        \n",
    "#     return theta0, thetas, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gradientDescent(X, Y, alpha, n_epoch):\n",
    "    m = Y.size\n",
    "    J = list()  \n",
    "    theta0 = np.array([0.0,0.0,0.0])\n",
    "    thetas = np.zeros([X.shape[1],3])\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for i in range(0,len(X),32):\n",
    "            h_x = Softmax(theta0 + np.dot(X[i:i+32],thetas))\n",
    "\n",
    "            theta0 = theta0 - (alpha) * np.dot(np.ones(X[i:i+32].shape[0]),h_x-Y[i:i+32])\n",
    "            thetas = thetas - (alpha) * np.dot(np.transpose(X[i:i+32]),h_x-Y[i:i+32])\n",
    "\n",
    "        J.append(computeCost(X,Y,theta0,thetas))\n",
    "        print(\"Epoch: \", epoch, \"    Cost: \",J[-1])\n",
    "    return theta0, thetas, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0     Cost:  0.31653569757559075\n",
      "Epoch:  1     Cost:  0.3083708110279897\n",
      "Epoch:  2     Cost:  0.29448825361623693\n",
      "Epoch:  3     Cost:  0.2828573686540157\n",
      "Epoch:  4     Cost:  0.2733211510510312\n",
      "Epoch:  5     Cost:  0.26537015829648997\n",
      "Epoch:  6     Cost:  0.2586230800346029\n",
      "Epoch:  7     Cost:  0.25280837984582766\n",
      "Epoch:  8     Cost:  0.2477296907807522\n",
      "Epoch:  9     Cost:  0.2432420660221072\n",
      "Epoch:  10     Cost:  0.23923643572914552\n",
      "Epoch:  11     Cost:  0.23562928262293376\n",
      "Epoch:  12     Cost:  0.232355637592369\n",
      "Epoch:  13     Cost:  0.22936423022547994\n",
      "Epoch:  14     Cost:  0.22661406827036795\n",
      "Epoch:  15     Cost:  0.22407198366466785\n",
      "Epoch:  16     Cost:  0.22171084434919028\n",
      "Epoch:  17     Cost:  0.21950823234966224\n",
      "Epoch:  18     Cost:  0.21744545342504243\n",
      "Epoch:  19     Cost:  0.21550678585965433\n",
      "Epoch:  20     Cost:  0.2136789040330933\n",
      "Epoch:  21     Cost:  0.21195043131522068\n",
      "Epoch:  22     Cost:  0.21031158976952466\n",
      "Epoch:  23     Cost:  0.20875392311634833\n",
      "Epoch:  24     Cost:  0.20727007570456396\n",
      "Epoch:  25     Cost:  0.20585361471524605\n",
      "Epoch:  26     Cost:  0.20449888603740657\n",
      "Epoch:  27     Cost:  0.20320089659291038\n",
      "Epoch:  28     Cost:  0.20195521760322915\n",
      "Epoch:  29     Cost:  0.20075790456231024\n",
      "Epoch:  30     Cost:  0.1996054306311362\n",
      "Epoch:  31     Cost:  0.1984946308874728\n",
      "Epoch:  32     Cost:  0.1974226554106149\n",
      "Epoch:  33     Cost:  0.19638692959994908\n",
      "Epoch:  34     Cost:  0.1953851204499232\n",
      "Epoch:  35     Cost:  0.19441510775598314\n",
      "Epoch:  36     Cost:  0.19347495942343776\n",
      "Epoch:  37     Cost:  0.19256291020686786\n",
      "Epoch:  38     Cost:  0.19167734333117067\n",
      "Epoch:  39     Cost:  0.19081677454385232\n",
      "Epoch:  40     Cost:  0.1899798382272271\n",
      "Epoch:  41     Cost:  0.18916527526293478\n",
      "Epoch:  42     Cost:  0.18837192239286532\n",
      "Epoch:  43     Cost:  0.18759870286267463\n",
      "Epoch:  44     Cost:  0.18684461816851722\n",
      "Epoch:  45     Cost:  0.18610874075593017\n",
      "Epoch:  46     Cost:  0.18539020754316968\n",
      "Epoch:  47     Cost:  0.18468821416066106\n",
      "Epoch:  48     Cost:  0.18400200981433698\n",
      "Epoch:  49     Cost:  0.1833308926940882\n",
      "Epoch:  50     Cost:  0.18267420585982821\n",
      "Epoch:  51     Cost:  0.18203133354715548\n",
      "Epoch:  52     Cost:  0.18140169784259913\n",
      "Epoch:  53     Cost:  0.18078475568520952\n",
      "Epoch:  54     Cost:  0.1801799961570064\n",
      "Epoch:  55     Cost:  0.17958693802970108\n",
      "Epoch:  56     Cost:  0.1790051275392927\n",
      "Epoch:  57     Cost:  0.17843413636372818\n",
      "Epoch:  58     Cost:  0.17787355978189412\n",
      "Epoch:  59     Cost:  0.17732301499486472\n",
      "Epoch:  60     Cost:  0.17678213959262123\n",
      "Epoch:  61     Cost:  0.1762505901514405\n",
      "Epoch:  62     Cost:  0.17572804094887465\n",
      "Epoch:  63     Cost:  0.17521418278473838\n",
      "Epoch:  64     Cost:  0.17470872189782816\n",
      "Epoch:  65     Cost:  0.17421137896923566\n",
      "Epoch:  66     Cost:  0.17372188820411882\n",
      "Epoch:  67     Cost:  0.1732399964846672\n",
      "Epoch:  68     Cost:  0.17276546258777156\n",
      "Epoch:  69     Cost:  0.17229805646158308\n",
      "Epoch:  70     Cost:  0.1718375585557487\n",
      "Epoch:  71     Cost:  0.17138375920063714\n",
      "Epoch:  72     Cost:  0.1709364580313399\n",
      "Epoch:  73     Cost:  0.1704954634526477\n",
      "Epoch:  74     Cost:  0.17006059214157185\n",
      "Epoch:  75     Cost:  0.16963166858431114\n",
      "Epoch:  76     Cost:  0.1692085246448572\n",
      "Epoch:  77     Cost:  0.16879099916269397\n",
      "Epoch:  78     Cost:  0.16837893757728287\n",
      "Epoch:  79     Cost:  0.167972191577234\n",
      "Epoch:  80     Cost:  0.1675706187722535\n",
      "Epoch:  81     Cost:  0.1671740823861266\n",
      "Epoch:  82     Cost:  0.1667824509691493\n",
      "Epoch:  83     Cost:  0.166395598128557\n",
      "Epoch:  84     Cost:  0.166013402275626\n",
      "Epoch:  85     Cost:  0.165635746388232\n",
      "Epoch:  86     Cost:  0.16526251778775491\n",
      "Epoch:  87     Cost:  0.16489360792930857\n",
      "Epoch:  88     Cost:  0.16452891220435825\n",
      "Epoch:  89     Cost:  0.1641683297548652\n",
      "Epoch:  90     Cost:  0.16381176329816413\n",
      "Epoch:  91     Cost:  0.16345911896184523\n",
      "Epoch:  92     Cost:  0.16311030612796662\n",
      "Epoch:  93     Cost:  0.16276523728597606\n",
      "Epoch:  94     Cost:  0.16242382789376875\n",
      "Epoch:  95     Cost:  0.162085996246351\n",
      "Epoch:  96     Cost:  0.16175166335161895\n",
      "Epoch:  97     Cost:  0.16142075281279814\n",
      "Epoch:  98     Cost:  0.16109319071712294\n",
      "Epoch:  99     Cost:  0.16076890553036596\n",
      "Epoch:  100     Cost:  0.16044782799685445\n",
      "Epoch:  101     Cost:  0.16012989104463746\n",
      "Epoch:  102     Cost:  0.15981502969549088\n",
      "Epoch:  103     Cost:  0.1595031809794694\n",
      "Epoch:  104     Cost:  0.15919428385373408\n",
      "Epoch:  105     Cost:  0.15888827912540415\n",
      "Epoch:  106     Cost:  0.1585851093781962\n",
      "Epoch:  107     Cost:  0.1582847189026329\n",
      "Epoch:  108     Cost:  0.1579870536296153\n",
      "Epoch:  109     Cost:  0.15769206106716807\n",
      "Epoch:  110     Cost:  0.15739969024017827\n",
      "Epoch:  111     Cost:  0.15710989163296085\n",
      "Epoch:  112     Cost:  0.156822617134494\n",
      "Epoch:  113     Cost:  0.1565378199861782\n",
      "Epoch:  114     Cost:  0.15625545473198155\n",
      "Epoch:  115     Cost:  0.1559754771708421\n",
      "Epoch:  116     Cost:  0.15569784431120734\n",
      "Epoch:  117     Cost:  0.15542251432759713\n",
      "Epoch:  118     Cost:  0.15514944651908344\n",
      "Epoch:  119     Cost:  0.15487860126958705\n",
      "Epoch:  120     Cost:  0.15460994000989808\n",
      "Epoch:  121     Cost:  0.15434342518133\n",
      "Epoch:  122     Cost:  0.1540790202009268\n",
      "Epoch:  123     Cost:  0.15381668942814167\n",
      "Epoch:  124     Cost:  0.15355639813291672\n",
      "Epoch:  125     Cost:  0.15329811246509165\n",
      "Epoch:  126     Cost:  0.15304179942507767\n",
      "Epoch:  127     Cost:  0.15278742683573343\n",
      "Epoch:  128     Cost:  0.15253496331538566\n",
      "Epoch:  129     Cost:  0.1522843782519392\n",
      "Epoch:  130     Cost:  0.15203564177802387\n",
      "Epoch:  131     Cost:  0.1517887247471295\n",
      "Epoch:  132     Cost:  0.15154359871068307\n",
      "Epoch:  133     Cost:  0.1513002358960226\n",
      "Epoch:  134     Cost:  0.15105860918522787\n",
      "Epoch:  135     Cost:  0.15081869209476717\n",
      "Epoch:  136     Cost:  0.15058045875592402\n",
      "Epoch:  137     Cost:  0.1503438838959674\n",
      "Epoch:  138     Cost:  0.1501089428200328\n",
      "Epoch:  139     Cost:  0.14987561139368194\n",
      "Epoch:  140     Cost:  0.14964386602611146\n",
      "Epoch:  141     Cost:  0.14941368365398133\n",
      "Epoch:  142     Cost:  0.14918504172583658\n",
      "Epoch:  143     Cost:  0.1489579181870961\n",
      "Epoch:  144     Cost:  0.14873229146558442\n",
      "Epoch:  145     Cost:  0.14850814045758262\n",
      "Epoch:  146     Cost:  0.1482854445143773\n",
      "Epoch:  147     Cost:  0.1480641834292853\n",
      "Epoch:  148     Cost:  0.14784433742513528\n",
      "Epoch:  149     Cost:  0.14762588714218672\n",
      "Epoch:  150     Cost:  0.14740881362646796\n",
      "Epoch:  151     Cost:  0.14719309831851612\n",
      "Epoch:  152     Cost:  0.14697872304250356\n",
      "Epoch:  153     Cost:  0.14676566999573312\n",
      "Epoch:  154     Cost:  0.14655392173848927\n",
      "Epoch:  155     Cost:  0.14634346118422972\n",
      "Epoch:  156     Cost:  0.14613427159010428\n",
      "Epoch:  157     Cost:  0.14592633654778825\n",
      "Epoch:  158     Cost:  0.14571963997461748\n",
      "Epoch:  159     Cost:  0.1455141661050139\n",
      "Epoch:  160     Cost:  0.1453098994821898\n",
      "Epoch:  161     Cost:  0.1451068249501201\n",
      "Epoch:  162     Cost:  0.14490492764577279\n",
      "Epoch:  163     Cost:  0.14470419299158746\n",
      "Epoch:  164     Cost:  0.14450460668819212\n",
      "Epoch:  165     Cost:  0.14430615470734975\n",
      "Epoch:  166     Cost:  0.14410882328512645\n",
      "Epoch:  167     Cost:  0.1439125989152719\n",
      "Epoch:  168     Cost:  0.14371746834280508\n",
      "Epoch:  169     Cost:  0.1435234185577972\n",
      "Epoch:  170     Cost:  0.14333043678934537\n",
      "Epoch:  171     Cost:  0.14313851049972917\n",
      "Epoch:  172     Cost:  0.14294762737874409\n",
      "Epoch:  173     Cost:  0.14275777533820547\n",
      "Epoch:  174     Cost:  0.14256894250661653\n",
      "Epoch:  175     Cost:  0.14238111722399518\n",
      "Epoch:  176     Cost:  0.14219428803685347\n",
      "Epoch:  177     Cost:  0.14200844369332447\n",
      "Epoch:  178     Cost:  0.14182357313843216\n",
      "Epoch:  179     Cost:  0.14163966550949783\n",
      "Epoch:  180     Cost:  0.14145671013167987\n",
      "Epoch:  181     Cost:  0.14127469651364172\n",
      "Epoch:  182     Cost:  0.141093614343343\n",
      "Epoch:  183     Cost:  0.1409134534839509\n",
      "Epoch:  184     Cost:  0.14073420396986686\n",
      "Epoch:  185     Cost:  0.1405558560028646\n",
      "Epoch:  186     Cost:  0.14037839994833676\n",
      "Epoch:  187     Cost:  0.14020182633164532\n",
      "Epoch:  188     Cost:  0.14002612583457322\n",
      "Epoch:  189     Cost:  0.13985128929187352\n",
      "Epoch:  190     Cost:  0.13967730768791295\n",
      "Epoch:  191     Cost:  0.1395041721534067\n",
      "Epoch:  192     Cost:  0.13933187396224203\n",
      "Epoch:  193     Cost:  0.13916040452838682\n",
      "Epoch:  194     Cost:  0.1389897554028814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  195     Cost:  0.13881991827091025\n",
      "Epoch:  196     Cost:  0.13865088494895167\n",
      "Epoch:  197     Cost:  0.13848264738200217\n",
      "Epoch:  198     Cost:  0.1383151976408743\n",
      "Epoch:  199     Cost:  0.13814852791956428\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 200\n",
    "alpha = 0.0005\n",
    "\n",
    "theta0,thetas,J = mini_batch_gradientDescent(train_features,train_labels,alpha,n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting cost against epoch to see the shift in loss per epoch\n",
    "x_axis = [i for i in range(1,n_epoch+1)]\n",
    "pyplot.plot(x_axis, J, 'bo', ms=0.5, mec='k')\n",
    "pyplot.ylabel('J (Cost Function)')\n",
    "pyplot.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING BEGINS HERE....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2929, 15903)\n",
      "(3,)\n",
      "(15903, 3)\n"
     ]
    }
   ],
   "source": [
    "#testing on the test data and then calculating Evaluation matrix for stocastic gradient descent\n",
    "# use test_labels here\n",
    "\n",
    "test_predictions = (predict(test_features, theta0, thetas)).tolist()\n",
    "# test_labels = (test_labels).tolist()\n",
    "predicted_results=[]\n",
    "for x in test_predictions:\n",
    "    if x.index(max(x)) == 0:\n",
    "        predicted_results.append([1,0,0])\n",
    "    elif x.index(max(x)) == 1:\n",
    "        predicted_results.append([0,1,0])\n",
    "    elif x.index(max(x)) == 2:\n",
    "        predicted_results.append([0,0,1])\n",
    "\n",
    "Evaluation_matrix = np.array(([0,0,0],[0,0,0],[0,0,0]))\n",
    "        \n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i][0] == 1:              #if true label is positive\n",
    "        if predicted_results[i][0] == 1:\n",
    "            Evaluation_matrix[0][0]+=1\n",
    "        elif predicted_results[i][1] == 1:\n",
    "            Evaluation_matrix[1][0]+=1\n",
    "        elif predicted_results[i][2] == 1:\n",
    "            Evaluation_matrix[2][0]+=1\n",
    "            \n",
    "    elif test_labels[i][1] == 1:            #if true label is neutral\n",
    "        if predicted_results[i][0] == 1:\n",
    "            Evaluation_matrix[0][1]+=1\n",
    "        elif predicted_results[i][1] == 1:\n",
    "            Evaluation_matrix[1][1]+=1\n",
    "        elif predicted_results[i][2] == 1:\n",
    "            Evaluation_matrix[2][1]+=1\n",
    "            \n",
    "    elif test_labels[i][2] == 1:            #if true label is negative\n",
    "        if predicted_results[i][0] == 1:\n",
    "            Evaluation_matrix[0][2]+=1\n",
    "        elif predicted_results[i][1] == 1:\n",
    "            Evaluation_matrix[1][2]+=1\n",
    "        elif predicted_results[i][2] == 1:\n",
    "            Evaluation_matrix[2][2]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................\n",
      "EVALUATION MATRIX: \n",
      "                     Gold Labels          \n",
      "                   | pos         neu         neg\n",
      "System Output  pos | 267         48           31\n",
      "               neu | 46          237          31\n",
      "               neg | 160         335          1774\n",
      "............................................................................................\n",
      "Macro-Precision:  0.7694318639615224\n",
      "Macro-Recall:  0.6376570103112033\n",
      "Macro-F1_Score:  0.6746070378518404\n",
      "\n",
      "Micro-Precision:  0.7777398429498122\n",
      "Micro-Recall:  0.7777398429498122\n",
      "Micro-F1_Score:  0.7777398429498122\n",
      "\n",
      "Accuracy:  0.7777398429498122\n",
      "Error:  0.22226015705018776\n"
     ]
    }
   ],
   "source": [
    "print(\"............................................................................................\")\n",
    "print(\"EVALUATION MATRIX: \")\n",
    "\n",
    "print (\"                     Gold Labels          \")\n",
    "print (\"                   | pos         neu         neg\")\n",
    "print(\"System Output  pos |\",Evaluation_matrix[0][0],\"       \",Evaluation_matrix[0][1],\"         \",Evaluation_matrix[0][2])\n",
    "print(\"               neu |\",Evaluation_matrix[1][0],\"        \",Evaluation_matrix[1][1],\"        \",Evaluation_matrix[1][2])\n",
    "print(\"               neg |\",Evaluation_matrix[2][0],\"       \",Evaluation_matrix[2][1],\"        \",Evaluation_matrix[2][2])\n",
    "print(\"............................................................................................\")\n",
    "\n",
    "pos_precision = Evaluation_matrix[0][0]/(Evaluation_matrix[0][0]+Evaluation_matrix[0][1]+Evaluation_matrix[0][2])\n",
    "neu_precision = Evaluation_matrix[1][1]/(Evaluation_matrix[1][0]+Evaluation_matrix[1][1]+Evaluation_matrix[1][2])\n",
    "neg_precision = Evaluation_matrix[2][2]/(Evaluation_matrix[2][0]+Evaluation_matrix[2][1]+Evaluation_matrix[2][2])\n",
    "\n",
    "pos_recall = Evaluation_matrix[0][0]/(Evaluation_matrix[0][0]+Evaluation_matrix[1][0]+Evaluation_matrix[2][0])\n",
    "neu_recall = Evaluation_matrix[1][1]/(Evaluation_matrix[0][1]+Evaluation_matrix[1][1]+Evaluation_matrix[2][1])\n",
    "neg_recall = Evaluation_matrix[2][2]/(Evaluation_matrix[0][2]+Evaluation_matrix[1][2]+Evaluation_matrix[2][2])\n",
    "\n",
    "pos_F1_score  = (2 * pos_precision * pos_recall)/(pos_precision + pos_recall)\n",
    "neu_F1_score  = (2 * neu_precision * neu_recall)/(neu_precision + neu_recall)\n",
    "neg_F1_score  = (2 * neg_precision * neg_recall)/(neg_precision + neg_recall)\n",
    "\n",
    "macro_precision = (pos_precision + neu_precision + neg_precision)/3\n",
    "macro_recall = (pos_recall + neu_recall + neg_recall)/3\n",
    "macro_F1_score = (pos_F1_score + neu_F1_score + neg_F1_score)/3\n",
    "\n",
    "micro_precision = (Evaluation_matrix[0][0] + Evaluation_matrix[1][1] + Evaluation_matrix[2][2])/len(test_features)\n",
    "micro_recall = (Evaluation_matrix[0][0] + Evaluation_matrix[1][1] + Evaluation_matrix[2][2])/len(test_features)\n",
    "micro_F1_score = (Evaluation_matrix[0][0] + Evaluation_matrix[1][1] + Evaluation_matrix[2][2])/len(test_features)\n",
    "\n",
    "accuracy = (Evaluation_matrix[0][0] + Evaluation_matrix[1][1] + Evaluation_matrix[2][2])/len(test_features)\n",
    "\n",
    "print(\"Macro-Precision: \",macro_precision)\n",
    "print(\"Macro-Recall: \",macro_recall)\n",
    "print(\"Macro-F1_Score: \",macro_F1_score)\n",
    "print()\n",
    "print(\"Micro-Precision: \",micro_precision)\n",
    "print(\"Micro-Recall: \",micro_recall)\n",
    "print(\"Micro-F1_Score: \",micro_F1_score)\n",
    "print()\n",
    "print(\"Accuracy: \",accuracy)\n",
    "print(\"Error: \", 1-accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
